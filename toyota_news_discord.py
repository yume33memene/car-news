#!/usr/bin/env python3
# japanese_car_news_colored.py
# requirements: feedparser, requests, beautifulsoup4
# (æ³¨) ã„ã™ã‚ / æ—¥é‡ / ä¸‰è±ãµãã† ã®ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»RSSã¯é™¤å¤–æ¸ˆã¿

import os
import json
import time
import hashlib
import feedparser
import requests
from bs4 import BeautifulSoup

# -----------------------
# è¨­å®š
# -----------------------
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")  # GitHub Secrets ã«ç™»éŒ²æ¸ˆã¿ã®ã‚‚ã®ã‚’ä½¿ç”¨
SENT_FILE = "sent_ids.json"
MAX_POSTS_PER_RUN = 8  # ä¸€å›ã®å®Ÿè¡Œã§Discordã«æŠ•ã’ã‚‹æœ€å¤§embedæ•°ï¼ˆWebhookã®åˆ¶é™ã«æ³¨æ„ï¼‰

# -----------------------
# ãƒ–ãƒ©ãƒ³ãƒ‰ => ã‚«ãƒ©ãƒ¼(hex) ãƒãƒƒãƒ—ï¼ˆæŒ‡å®šã®3ç¤¾ã‚’é™¤å¤–æ¸ˆã¿ï¼‰
# -----------------------
BRAND_COLORS = {
    "ãƒˆãƒ¨ã‚¿": 0xE60012,        # ãƒˆãƒ¨ã‚¿èµ¤
    "ãƒ¬ã‚¯ã‚µã‚¹": 0xD4AF37,      # ã‚´ãƒ¼ãƒ«ãƒ‰é¢¨
    "GR": 0xE74C3C,            # GRç³»ã¯èµ¤å¯„ã‚Š
    "GR86": 0xE74C3C,          # GR86ã¯ç‰¹åˆ¥æ‰±ã„ï¼ˆèµ¤ï¼‰
    "ãƒ›ãƒ³ãƒ€": 0x1E90FF,        # é’
    "æ—¥ç”£": 0xFF4500,          # ã‚ªãƒ¬ãƒ³ã‚¸ç³»
    "ãƒãƒ„ãƒ€": 0x8B0000,        # æ¿ƒèµ¤
    "ã‚¹ãƒãƒ«": 0x0033A0,        # ã‚¹ãƒãƒ«é’
    "ä¸‰è±": 0x990000,
    "ã‚¹ã‚ºã‚­": 0x0066CC,
    "ãƒ€ã‚¤ãƒãƒ„": 0xFF0000,
    # ãƒ¡ãƒ‡ã‚£ã‚¢ç³»ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰
    "Car Watch": 0x666666,
    "ãƒ™ã‚¹ãƒˆã‚«ãƒ¼": 0x666666,
}

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šã«ä½¿ã†ãƒ–ãƒ©ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼ˆBRAND_COLORS ã®ã‚­ãƒ¼ã‹ã‚‰ç”Ÿæˆï¼‰
BRAND_KEYWORDS = [k for k in BRAND_COLORS.keys()]

# -----------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -----------------------
def load_sent_ids():
    if not os.path.exists(SENT_FILE):
        return set()
    try:
        with open(SENT_FILE, "r", encoding="utf-8") as f:
            return set(json.load(f))
    except Exception:
        return set()

def save_sent_ids(s):
    with open(SENT_FILE, "w", encoding="utf-8") as f:
        json.dump(sorted(list(s)), f, ensure_ascii=False, indent=2)

def short(text, n=220):
    if not text:
        return ""
    t = " ".join(text.split())
    return (t[: n - 1] + "â€¦") if len(t) > n else t

def fetch_og_image(url):
    """OGPç”»åƒã‚’å–å¾—ï¼ˆå¯èƒ½ãªã‚‰ï¼‰"""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, timeout=6, headers=headers)
        if r.status_code != 200:
            return None
        from bs4 import BeautifulSoup as _BS
        soup = _BS(r.text, "html.parser")
        og = soup.find("meta", property="og:image")
        if og and og.get("content"):
            return og["content"]
        tc = soup.find("meta", attrs={"name":"twitter:image"})
        if tc and tc.get("content"):
            return tc["content"]
    except Exception:
        return None
    return None

def detect_brand(title, summary=""):
    """ã‚¿ã‚¤ãƒˆãƒ«ï¼‹è¦ç´„ã‹ã‚‰ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’æ¤œå‡ºï¼ˆæœ€åˆã«è¦‹ã¤ã‘ãŸãƒ–ãƒ©ãƒ³ãƒ‰ã‚’è¿”ã™ï¼‰"""
    text = (title + " " + summary).lower()
    for k in BRAND_KEYWORDS:
        if k.lower() in text:
            return k
    return None

def is_gr86_text(title, summary=""):
    t = (title + " " + summary).lower()
    if "gr86" in t.replace(" ", "") or "gr-86" in t or "ï¼§ï¼²ï¼˜ï¼–" in title or "GR86" in title:
        return True
    if "86" in t and "gr" in t:
        return True
    return False

# -----------------------
# RSSãƒ•ã‚£ãƒ¼ãƒ‰ä¸€è¦§ï¼ˆæŒ‡å®š3ç¤¾ã®RSSã¯é™¤å¤–æ¸ˆã¿ï¼‰
# -----------------------
RSS_URLS = [
    "https://global.toyota/export/jp/allnews_rss.xml",
    "https://global.toyota/jp/newsroom/toyota/rss.xml",
    "https://global.toyota/jp/newsroom/lexus/rss.xml",
    "https://toyotagazooracing.com/jp/rss.xml",

    "https://www.honda.co.jp/rss/",
    "https://global.nissannews.com/ja-JP/rss",
    "https://newsroom.mazda.com/ja_JP/rss.xml",
    "https://www.subaru.co.jp/news/rss.xml",
    "https://www.mitsubishi-motors.com/jp/newsrelease/rss.xml",
    "https://www.suzuki.co.jp/release/rss.xml",
    "https://www.daihatsu.co.jp/news/rss.xml",

    # è‡ªå‹•è»Šãƒ¡ãƒ‡ã‚£ã‚¢ï¼ˆè£œåŠ©ï¼‰
    "https://car.watch.impress.co.jp/docs/common/rss.xml",
    "https://bestcarweb.jp/rss",
]

# -----------------------
# DiscordæŠ•ç¨¿å‡¦ç†
# -----------------------
def make_embed_obj(title, link, brand=None, summary="", image=None, is_gr86=False):
    # è‰²ã®æ±ºå®š
    color = BRAND_COLORS.get(brand, 0x2D9CDB) if brand else 0x2D9CDB
    if is_gr86:
        color = BRAND_COLORS.get("GR86", color)

    desc = short(summary, 260)
    embed = {
        "title": ("ğŸ”¥ GR86é€Ÿå ±ï¼š " if is_gr86 else "") + title,
        "url": link,
        "description": desc,
        "color": color,
        "fields": [
            {"name": "ãƒ–ãƒ©ãƒ³ãƒ‰", "value": brand or "ï¼ˆä¸æ˜ï¼‰", "inline": True},
        ],
    }
    if image:
        embed["image"] = {"url": image}
    return embed

def post_embeds_to_discord(embeds):
    if not WEBHOOK_URL:
        print("âŒ DISCORD_WEBHOOK ãŒæœªè¨­å®šã§ã™ï¼ˆSecretsã«ç™»éŒ²ã—ã¦ãã ã•ã„ï¼‰")
        return False
    payload = {"embeds": embeds}
    try:
        r = requests.post(WEBHOOK_URL, json=payload, timeout=10)
        if r.status_code in (200, 204):
            return True
        else:
            print("âš ï¸ DiscordæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼:", r.status_code, r.text)
            return False
    except Exception as e:
        print("âŒ Discordé€ä¿¡ä¾‹å¤–:", e)
        return False

# -----------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# -----------------------
def fetch_all_entries():
    entries = []
    seen_links = set()
    for url in RSS_URLS:
        try:
            feed = feedparser.parse(url)
            if hasattr(feed, "entries"):
                for en in feed.entries:
                    link = en.get("link") or en.get("id") or ""
                    if not link:
                        continue
                    if link in seen_links:
                        continue
                    seen_links.add(link)
                    entries.append(en)
        except Exception as e:
            print("RSSå–å¾—ã‚¨ãƒ©ãƒ¼:", url, e)
    return entries

def main():
    sent = load_sent_ids()
    new_sent = set(sent)

    entries = fetch_all_entries()
    print(f"å–å¾—ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(entries)}")

    candidates = []
    for en in entries:
        uid = en.get("id", en.get("link"))
        if not uid or uid in sent:
            continue
        title = en.get("title", "") or ""
        summary = (en.get("summary") or en.get("description") or "") or ""
        brand = detect_brand(title, summary)
        gr86 = is_gr86_text(title, summary)
        if not brand and not gr86:
            continue
        link = en.get("link", "")
        candidates.append((gr86, brand or "ï¼ˆä¸æ˜ï¼‰", uid, title, summary, link))

    candidates.sort(key=lambda x: (0 if x[0] else 1))

    to_send = candidates[:MAX_POSTS_PER_RUN]
    print(f"é€ä¿¡å€™è£œæ•°: {len(to_send)}")

    embeds_batch = []
    for gr86, brand, uid, title, summary, link in to_send:
        image = fetch_og_image(link)
        embed = make_embed_obj(title, link, brand=brand, summary=summary, image=image, is_gr86=gr86)
        embeds_batch.append(embed)
        new_sent.add(uid)

    if embeds_batch:
        ok = post_embeds_to_discord(embeds_batch)
        if ok:
            save_sent_ids(new_sent)
            print(f"âœ… {len(embeds_batch)}ä»¶é€ä¿¡å®Œäº†")
        else:
            print("âŒ DiscordæŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        print("âœ… 0ä»¶é€ä¿¡å®Œäº†ï¼ˆæ–°ç€ãªã—ã¾ãŸã¯å¯¾è±¡å¤–ï¼‰")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼:", e)
